{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c86b0a8",
   "metadata": {},
   "source": [
    "# Scottish Election Voting Outcomes\n",
    "> Scottish local elections operate under a Single Transferable Vote (STV) system. Each voter is free to rank as many candidates as they like. If their first choice drops out of the race due to not reaching the required nr of votes, their second choice receives their vote instead, and so on. In this project, we look to aggregate vote counts from 338 wards across Scotland from a range of file types into one comprehensive cleaned csv.\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: false\n",
    "- comments: true\n",
    "- categories: [fastpages, jupyter]\n",
    "- image: images/elections.jpeg\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e13626",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309ce5a0",
   "metadata": {},
   "source": [
    "Local election outcomes are collected and aggregated at ward level. Each ward or county has variations in how outcomes are recorded, formatted and filed. \n",
    "\n",
    "This project demonstrates how object-oriented programming can be used to create ETL pipelines to unify all these files into national-level data. \n",
    "\n",
    "We define a class of data transformers to:\n",
    "\n",
    "- **Extract** text data from 330 files with 5 different types: .csv, .txt, .xls, .xlsx, and .blt\n",
    "- **Transform** this data through a series of steps detailed below, and \n",
    "- **Load** an aggregated .csv file back into the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5778a75",
   "metadata": {},
   "source": [
    "## File Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a788583d",
   "metadata": {},
   "source": [
    "The 330 files all have similar structures. \n",
    "Each row represents a possible voting pattern, i.e. a possible combination of ranking candidates, along with the nr of times that particular combination occured. For example:\n",
    "\n",
    "`122, 4, 2, 3, 1, 6`\n",
    "\n",
    "represents that 122 votes were cast with the first preference going to candidate 4. Should that candidate drop out of the race, the vote should go to candidate 2, and so forth.\n",
    "\n",
    "The second to last row of the file lists the candidates and their party affiliations. The nr in the votes correspond to their ordering. i.e. `1` refers to the first candidate in the list, and the party they belong to.\n",
    "\n",
    "The last row in the file cites the ward the data corresponds to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f705fa4",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154494dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b870604e",
   "metadata": {},
   "source": [
    "## Class Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c9321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os, os.path\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245e015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_object(path):\n",
    "    \n",
    "    # Dictionary pointing to the correct Class for each file extension\n",
    "    object_map = {\n",
    "        'csv' : Ward_Data_csv,\n",
    "        'xls': Ward_Data_csv,\n",
    "        'txt' : Ward_Data_txt,\n",
    "        'blt' : Ward_Data_txt,\n",
    "        'xlsx': Ward_Data_xlsx\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # Determine the file extension\n",
    "    extension = path[2:].split('.')[1]\n",
    "    assert extension in object_map, 'Invalid file type. Must be csv, xls, xlsx, txt or blt'\n",
    "    \n",
    "    # return the corresponding object \n",
    "    return object_map[extension](path)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26e7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import subsets\n",
    "\n",
    "\n",
    "class Ward_Data():\n",
    "    \n",
    "    '''\n",
    "    The default assumed filetype for the superclass is .csv\n",
    "    Generally, the correct subclass should be used instead:\n",
    "    Ward_Data_csv, Ward_Data_txt, Ward_data_xlsx\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        return\n",
    "    \n",
    "    def read_data(self):\n",
    "        # Check if top row contains text\n",
    "        \n",
    "        # Read in data\n",
    "        self.data = pd.read_csv(self.path, header = None, delimiter = ';')\n",
    "        #print(self.data.shape)\n",
    "        \n",
    "        assert self.data.shape[1] == 1, f'Unexpected nr of columns. Found {self.data.shape[1]} columns but expected 1'\n",
    "        assert self.data.shape[0] > 0, f'No rows detected'\n",
    "        \n",
    "        # If bottom row contains escape character, remove.\n",
    "        assert '\\\\' not in WD.data.iloc[-1, 0], 'Escape character found in bottom row'\n",
    "        \n",
    "    def extract_ward_ID(self):\n",
    "        # Extract the last row as the ward ID\n",
    "        #print(self.data.iloc[-1, 0])\n",
    "        #assert bool(re.match(r\"[A-z]\", self.data.iloc[-1, 0])) == True, \"Can't find characters in last row of dataframe\"\n",
    "        self.ward_ID = self.data.iloc[-1, 0]\n",
    "        # Clean up trailing white space\n",
    "        self.ward_ID = self.ward_ID.strip()\n",
    "        \n",
    "        self.data = self.data[:-1]\n",
    "    \n",
    "    def extract_candidates(self):\n",
    "        self.candidates = list(self.data[self.data[0].str.contains('[A-z]', na = False)][0])\n",
    "        \n",
    "        # Account for inconsistent formatting: either [\"candidate_name\" \"Party_name\"] or [candidate_name \"Party_name\"]\n",
    "        try:\n",
    "            self.parties = [x.split('\" \"')[1].replace('\"', '') for x in self.candidates]\n",
    "        except:\n",
    "            self.parties = [x.split('\"')[1].replace('\"', '') for x in self.candidates]\n",
    "            \n",
    "        self.parties = [x if x != '' else 'Independent' for x in self.parties]\n",
    "        self.data = self.data[~self.data[0].str.contains('[A-z]', na = False)]\n",
    "        \n",
    "    def split_votes(self):\n",
    "        # Remove 'end of data' indicator if any\n",
    "        if self.data.iloc[-1,0] == '0':\n",
    "            self.data = self.data[:-1]\n",
    "            \n",
    "        # Remove trailing zeroes and whitespace if any    \n",
    "        self.data[0] = self.data[0].str.replace(' 0', '')\n",
    "        self.data[0] = self.data[0].str.strip()\n",
    "        # Remove extra whitespace between entries\n",
    "        self.data[0] = self.data[0].str.replace(r'[ ]{2,}', ' ')\n",
    "\n",
    "        \n",
    "        # Split vote counts\n",
    "        self.split_votes = self.data[0].str.split('\\s', expand = True)\n",
    "        \n",
    "        # Rename vote count column\n",
    "        self.split_votes = self.split_votes.rename(columns = {0:'Count'})\n",
    "        self.counts = self.split_votes['Count']\n",
    "        self.split_votes.drop('Count', axis = 1, inplace = True)\n",
    "    \n",
    "    def replace_parties(self):\n",
    "        \n",
    "        for x in range(len(self.parties)):\n",
    "            self.split_votes.replace(str(x+1), self.parties[x], inplace = True)\n",
    "            \n",
    "    def combine(self):\n",
    "        \n",
    "        self.clean_data = self.split_votes.merge(self.counts, left_index=True, right_index=True)\n",
    "        self.clean_data['Ward'] = self.ward_ID\n",
    "        #print(self.clean_data)\n",
    "        self.clean_data.dropna(subset=1)\n",
    "        #print(self.clean_data[self.clean_data.isna()])\n",
    "        self.clean_data.insert(0, 'Count', self.clean_data.pop('Count').dropna().astype('int'))\n",
    "        self.clean_data.insert(0, 'Ward', self.clean_data.pop('Ward'))\n",
    "        self.clean_data.dropna(subset='Count', inplace = True)\n",
    "        \n",
    "    def sort_by_count(self):\n",
    "        self.clean_data = self.clean_data.sort_values(by='Count', ascending = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588e3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ward_Data_txt(Ward_Data):\n",
    "    def read_data(self):\n",
    "        # Check if top row contains text\n",
    "        \n",
    "        # Read in data\n",
    "        self.data = pd.read_csv(self.path, header = None, delimiter = ';')\n",
    "        \n",
    "        assert self.data.shape[1] == 1, f'Unexpected nr of columns. Found {self.data.shape[1]} columns but expected 1'\n",
    "        assert self.data.shape[0] > 0, f'No rows detected'\n",
    "\n",
    "        \n",
    "        # If bottom row contains escape character, remove.\n",
    "        if self.data.iloc[-1, 0] == '\\x0c':\n",
    "            self.data = self.data.iloc[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97df04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ward_Data_csv(Ward_Data):\n",
    "    \n",
    "    def read_data(self):\n",
    "        # Check if top row contains text\n",
    "        \n",
    "        # Read in data\n",
    "        self.data = pd.read_csv(self.path, header = None, delimiter = ';')\n",
    "        #print(self.data.shape)\n",
    "        \n",
    "        assert self.data.shape[1] == 1, f'Unexpected nr of columns. Found {self.data.shape[1]} columns but expected 1'\n",
    "        assert self.data.shape[0] > 0, f'No rows detected'\n",
    "        \n",
    "        # If bottom row contains escape character, remove.\n",
    "        assert '\\\\' not in self.data.iloc[-1, 0], 'Escape character found in bottom row'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e814b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ward_Data_xlsx(Ward_Data):\n",
    "    \n",
    "    def read_data(self):\n",
    "        # Check if top row contains text\n",
    "        \n",
    "        # Read in data\n",
    "        self.data = pd.read_excel(self.path, header = None)\n",
    "        \n",
    "        assert self.data.shape[1] == 1, f'Unexpected nr of columns. Found {self.data.shape[1]} columns but expected 1'\n",
    "        assert self.data.shape[0] > 0, f'No rows detected'\n",
    "        \n",
    "        # If bottom row contains escape character, remove.\n",
    "        assert '\\\\' not in self.data.iloc[-1, 0], 'Escape character found in bottom row'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942d800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3922116b",
   "metadata": {},
   "source": [
    "## Main program function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e878666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    master_data = pd.DataFrame()\n",
    "    completed_records = []\n",
    "    nr_files = len(os.listdir('../_data/'))\n",
    "    process_count = 0\n",
    "    duplicates = []\n",
    "\n",
    "    for file in glob.glob('../_data/*'):\n",
    "        if process_count % 10 == 0:\n",
    "            print(f'Processed {process_count} / {nr_files} files')\n",
    "        WD = create_object(file)\n",
    "        WD.read_data()\n",
    "        WD.extract_ward_ID()\n",
    "\n",
    "        if WD.ward_ID in completed_records:\n",
    "            duplicates.append(WD.path)\n",
    "            print('Ward already processed')\n",
    "            continue\n",
    "        else:\n",
    "            completed_records.append(WD.ward_ID)\n",
    "\n",
    "        \n",
    "\n",
    "        WD.extract_candidates()\n",
    "        WD.split_votes()\n",
    "        WD.replace_parties()\n",
    "        WD.combine()\n",
    "        WD.sort_by_count()\n",
    "        master_data = pd.concat([master_data, WD.clean_data])\n",
    "        \n",
    "        process_count += 1\n",
    "    \n",
    "    print(f'{process_count} files processed. {len(duplicates)} duplicate wards identified')\n",
    "    \n",
    "    return master_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d52797",
   "metadata": {},
   "source": [
    "## Run the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553d798a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 / 319 files\n",
      "Processed 10 / 319 files\n",
      "Processed 20 / 319 files\n",
      "Processed 30 / 319 files\n",
      "Processed 40 / 319 files\n",
      "Processed 50 / 319 files\n",
      "Processed 60 / 319 files\n",
      "Processed 70 / 319 files\n",
      "Processed 80 / 319 files\n",
      "Processed 90 / 319 files\n",
      "Ward already processed\n",
      "Processed 100 / 319 files\n",
      "Processed 110 / 319 files\n",
      "Ward already processed\n",
      "Processed 120 / 319 files\n",
      "Processed 130 / 319 files\n",
      "Processed 140 / 319 files\n",
      "Ward already processed\n",
      "Processed 150 / 319 files\n",
      "Processed 160 / 319 files\n",
      "Processed 170 / 319 files\n",
      "Ward already processed\n",
      "Processed 170 / 319 files\n",
      "Ward already processed\n",
      "Processed 170 / 319 files\n",
      "Processed 180 / 319 files\n",
      "Processed 190 / 319 files\n",
      "Processed 200 / 319 files\n",
      "Processed 210 / 319 files\n",
      "Ward already processed\n",
      "Processed 220 / 319 files\n",
      "Processed 230 / 319 files\n",
      "Ward already processed\n",
      "Processed 240 / 319 files\n",
      "Ward already processed\n",
      "Processed 250 / 319 files\n",
      "Processed 260 / 319 files\n",
      "Processed 270 / 319 files\n",
      "Processed 280 / 319 files\n",
      "Processed 290 / 319 files\n",
      "Processed 300 / 319 files\n",
      "Ward already processed\n",
      "Ward already processed\n",
      "308 files processed. 10 duplicate wards identified\n"
     ]
    }
   ],
   "source": [
    "master_data = main()\n",
    "master_data.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feedacf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ward</th>\n",
       "      <th>Count</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ward 5 - Heldon and Laich</td>\n",
       "      <td>412.0</td>\n",
       "      <td>Scottish National Party (SNP)</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ward 5 - Heldon and Laich</td>\n",
       "      <td>333.0</td>\n",
       "      <td>Scottish Conservative and Unionist</td>\n",
       "      <td>Scottish Conservative and Unionist</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ward 5 - Heldon and Laich</td>\n",
       "      <td>217.0</td>\n",
       "      <td>Scottish Conservative and Unionist</td>\n",
       "      <td>Scottish Conservative and Unionist</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ward 5 - Heldon and Laich</td>\n",
       "      <td>173.0</td>\n",
       "      <td>Scottish Conservative and Unionist</td>\n",
       "      <td>Scottish Conservative and Unionist</td>\n",
       "      <td>Independent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ward 5 - Heldon and Laich</td>\n",
       "      <td>142.0</td>\n",
       "      <td>Independent</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Ward  Count                                   1  \\\n",
       "0  Ward 5 - Heldon and Laich  412.0       Scottish National Party (SNP)   \n",
       "1  Ward 5 - Heldon and Laich  333.0  Scottish Conservative and Unionist   \n",
       "2  Ward 5 - Heldon and Laich  217.0  Scottish Conservative and Unionist   \n",
       "3  Ward 5 - Heldon and Laich  173.0  Scottish Conservative and Unionist   \n",
       "4  Ward 5 - Heldon and Laich  142.0                         Independent   \n",
       "\n",
       "                                    2            3     4     5     6    7  \\\n",
       "0                                None         None  None  None  None  NaN   \n",
       "1  Scottish Conservative and Unionist         None  None  None  None  NaN   \n",
       "2  Scottish Conservative and Unionist         None  None  None  None  NaN   \n",
       "3  Scottish Conservative and Unionist  Independent  None  None  None  NaN   \n",
       "4                                None         None  None  None  None  NaN   \n",
       "\n",
       "     8    9   10   11   12   13  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b95aba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data.to_csv('../_output/scottish_elections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f786265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5dfff79661a25005b578de8e9f7031277ad23c29239ce402491965601e5b1625"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
